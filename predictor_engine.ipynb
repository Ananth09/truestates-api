{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cb0f862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%d-%m-%Y'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATE_FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a476c49-6920-449d-ad2b-4b3ef3372d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import configparser\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "# Load configuration with interpolation disabled (prevents issues with % in DATE_FORMAT)\n",
    "CONFIG_FILE = 'config.ini'\n",
    "cfg = configparser.ConfigParser(interpolation=None)\n",
    "cfg.read(CONFIG_FILE)\n",
    "\n",
    "# --- CONFIGURATION CONSTANTS ---\n",
    "OHE_FILE = cfg.get('GENERAL', 'OHE_FILE', fallback='onehot_encoder.pkl')\n",
    "COLUMNS_FILE = cfg.get('GENERAL', 'COLUMNS_FILE', fallback='train_columns.pkl')\n",
    "TRAINING_DATA_FILE = cfg.get('GENERAL', 'TRAINING_DATA_FILE', fallback='df_trained_dataset_6000.csv')\n",
    "FORECAST_DATA_FILE = cfg.get('GENERAL', 'FORECAST_DATA_FILE', fallback='Sarima_forecast_6M.csv')\n",
    "\n",
    "try:\n",
    "    LOESS_FRAC = cfg.getfloat('GENERAL', 'LOESS_FRAC', fallback=0.1)\n",
    "except Exception:\n",
    "    LOESS_FRAC = 0.1\n",
    "try:\n",
    "    LOESS_IT = cfg.getint('GENERAL', 'LOESS_IT', fallback=3)\n",
    "except Exception:\n",
    "    LOESS_IT = 3\n",
    "\n",
    "DATE_FORMAT = cfg.get('GENERAL', 'DATE_FORMAT', fallback='%d-%m-%Y')  # Standard DD-MM-YYYY format\n",
    "\n",
    "class PropertyPricePredictor:\n",
    "    \"\"\"\n",
    "    A modular class to load models and data, prepare inputs, predict property\n",
    "    prices, and perform historical trend and future forecast analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    # AREA_FILE_MAP will be populated from `config.ini` (section: AREA_FILE_PATHS)\n",
    "    # Keys in the config are simplified area identifiers (e.g. al_barsha_south_fifth)\n",
    "    # Values are full paths to the .pkl model files.\n",
    "    AREA_FILE_MAP = {}\n",
    "\n",
    "    def __init__(self):\n",
    "        # Read area file paths from config and then load models\n",
    "        self.AREA_FILE_MAP = self._read_area_file_paths()\n",
    "        self.area_models = self._load_area_models()\n",
    "        self.ohe, self.train_columns = self._load_encoder_and_columns()\n",
    "        self.train_data = self._load_training_data()\n",
    "        self.growth_pivot = self._load_forecasting_data()\n",
    "\n",
    "        if not self.area_models:\n",
    "            print(\"‚ùå WARNING: No area models loaded. Prediction will fail.\")\n",
    "        if self.ohe is None or self.train_columns is None:\n",
    "            print(\"‚ùå WARNING: Encoder or training columns failed to load.\")\n",
    "\n",
    "    def _load_area_models(self) -> dict:\n",
    "        loaded_models = {}\n",
    "        missing_models = []\n",
    "        # AREA_FILE_MAP contains {config_key: full_path}; load and map to display name\n",
    "        for cfg_key, model_path in self.AREA_FILE_MAP.items():\n",
    "            # Derive the displayable area name from the model filename (keeps capitalization and apostrophes)\n",
    "            try:\n",
    "                basename = os.path.basename(model_path)\n",
    "                area_name = basename.replace('dt_model_', '').replace('.pkl', '').replace('_', ' ').strip()\n",
    "                # Validate file existence\n",
    "                if not os.path.exists(model_path):\n",
    "                    raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "                with open(model_path, 'rb') as f:\n",
    "                    loaded_models[area_name] = pickle.load(f)\n",
    "            except FileNotFoundError:\n",
    "                missing_models.append(model_path)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading {model_path}: {e}\")\n",
    "        if missing_models:\n",
    "            print(f\"‚ö†Ô∏è Missing models: {len(missing_models)} files could not be found. (This is expected in a sandbox environment without the actual files.)\")\n",
    "        return loaded_models\n",
    "\n",
    "    def _read_area_file_paths(self) -> dict:\n",
    "        \"\"\"Read AREA_FILE_PATHS section from CONFIG_FILE and return a dict of key->path.\"\"\"\n",
    "        try:\n",
    "            read_files = cfg.read(CONFIG_FILE)\n",
    "            if not read_files:\n",
    "                print(f\"‚ö†Ô∏è Could not read config file: {CONFIG_FILE}. Using empty area map.\")\n",
    "                return {}\n",
    "            if 'AREA_FILE_PATHS' not in cfg:\n",
    "                print(f\"‚ö†Ô∏è 'AREA_FILE_PATHS' section not found in {CONFIG_FILE}. Using empty area map.\")\n",
    "                return {}\n",
    "            # configparser lower-cases option names by default; values remain as provided\n",
    "            return dict(cfg['AREA_FILE_PATHS'])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading config file {CONFIG_FILE}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _load_encoder_and_columns(self):\n",
    "        ohe = None\n",
    "        train_columns = None\n",
    "        try:\n",
    "            # Mock loading since actual files are not present in this context\n",
    "            if not os.path.exists(OHE_FILE):\n",
    "                raise FileNotFoundError(f\"OHE file not found: {OHE_FILE}\")\n",
    "            with open(OHE_FILE, 'rb') as f:\n",
    "                ohe = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading One-Hot Encoder: {e}\")\n",
    "        try:\n",
    "            # Mock loading since actual files are not present in this context\n",
    "            if not os.path.exists(COLUMNS_FILE):\n",
    "                raise FileNotFoundError(f\"Columns file not found: {COLUMNS_FILE}\")\n",
    "            with open(COLUMNS_FILE, 'rb') as f:\n",
    "                train_columns = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading Training Columns: {e}\")\n",
    "        return ohe, train_columns\n",
    "\n",
    "    def _load_training_data(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            # Mock loading since actual files are not present in this context\n",
    "            if not os.path.exists(TRAINING_DATA_FILE):\n",
    "                raise FileNotFoundError(f\"Training data file not found: {TRAINING_DATA_FILE}\")\n",
    "\n",
    "            train_data = pd.read_csv(TRAINING_DATA_FILE)\n",
    "            train_data['instance_date'] = pd.to_datetime(train_data['instance_date'])\n",
    "            return train_data\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Could not load training data for trend analysis: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _load_forecasting_data(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            # Mock loading since actual files are not present in this context\n",
    "            if not os.path.exists(FORECAST_DATA_FILE):\n",
    "                raise FileNotFoundError(f\"Forecast data file not found: {FORECAST_DATA_FILE}\")\n",
    "\n",
    "            growth_df = pd.read_csv(FORECAST_DATA_FILE)\n",
    "            return growth_df\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading forecasting data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def prepare_input_data(self, area, rooms, floor, pool, balcony_val, elevator_val, metro_val, parking, area_size):\n",
    "        input_data = pd.DataFrame({\n",
    "            'rooms_en': [rooms], 'floor_bin': [floor], 'swimming_pool': [pool],\n",
    "            'balcony': [balcony_val], 'elevator': [elevator_val], 'metro': [metro_val],\n",
    "            'has_parking': [parking], 'area_name_en': [area], 'procedure_area': [area_size]\n",
    "        })\n",
    "        area_name = input_data['area_name_en'].iloc[0]\n",
    "        input_no_area = input_data.drop(columns=['area_name_en'])\n",
    "        cat_cols = ['rooms_en', 'floor_bin']\n",
    "        if self.ohe is None or self.train_columns is None:\n",
    "            return None, None, None\n",
    "        try:\n",
    "            X_cat = self.ohe.transform(input_no_area[cat_cols])\n",
    "            feature_names = self.ohe.get_feature_names_out(cat_cols)\n",
    "            X_cat_df = pd.DataFrame(X_cat.toarray() if hasattr(X_cat, 'toarray') else X_cat, columns=feature_names)\n",
    "            X_numerical = input_no_area.drop(columns=cat_cols)\n",
    "            X_processed = pd.concat([X_numerical.reset_index(drop=True), X_cat_df.reset_index(drop=True)], axis=1)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in encoding input: {e}\")\n",
    "            return None, None, None\n",
    "        final_X = pd.DataFrame(0, index=X_processed.index, columns=self.train_columns)\n",
    "        for col in X_processed.columns:\n",
    "             if col in final_X.columns:\n",
    "                 final_X[col] = X_processed[col]\n",
    "        return final_X, area_name, input_data\n",
    "\n",
    "    # Modified filter to ONLY filter by area name (Tier 3)\n",
    "    def filter_training_data_by_area_only(self, train_data, area_name):\n",
    "        if train_data is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Filter only by area name, ignoring all other property features\n",
    "        filtered_data = train_data[train_data['area_name_en'] == area_name].copy()\n",
    "\n",
    "        return filtered_data\n",
    "\n",
    "    # Combined trend calculation, now specialized for Area Trend\n",
    "    def calculate_area_trend(self, filtered_data):\n",
    "        \"\"\"Calculates LOESS trend for the entire area, returning a formatted DataFrame or None.\"\"\"\n",
    "        TREND_TYPE = 'Historical Trend (Entire Area)'\n",
    "\n",
    "        if filtered_data is None or len(filtered_data) < 2:\n",
    "            return pd.DataFrame({'Month': [], 'Median Price': [], 'Type': []})\n",
    "\n",
    "        filtered = filtered_data.copy()\n",
    "        filtered['instance_date'] = pd.to_datetime(filtered['instance_date'])\n",
    "        filtered['year_month'] = filtered['instance_date'].dt.to_period('M')\n",
    "        monthly_data = filtered.groupby('year_month')['meter_sale_price'].agg(['median', 'count']).reset_index()\n",
    "        monthly_data = monthly_data.rename(columns={'median': 'meter_sale_price', 'count': 'data_points'})\n",
    "        monthly_data['timestamp'] = monthly_data['year_month'].dt.to_timestamp()\n",
    "        monthly_data = monthly_data.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "        if len(monthly_data) < 2:\n",
    "            return pd.DataFrame({'Month': [], 'Median Price': [], 'Type': []})\n",
    "\n",
    "        try:\n",
    "            # Ensure numeric arrays\n",
    "            monthly_data['num_index'] = np.arange(len(monthly_data))\n",
    "            y_values = monthly_data['meter_sale_price'].astype(float).values\n",
    "            x_values = monthly_data['num_index'].astype(float).values\n",
    "\n",
    "            # Coerce LOESS parameters to numeric with safe fallbacks\n",
    "            try:\n",
    "                frac = float(LOESS_FRAC)\n",
    "            except Exception:\n",
    "                frac = 0.1\n",
    "            try:\n",
    "                iters = int(LOESS_IT)\n",
    "            except Exception:\n",
    "                iters = 3\n",
    "\n",
    "            loess_smoothed = lowess(y_values, x_values, frac=frac, it=iters)\n",
    "\n",
    "            # Validate LOESS output\n",
    "            if loess_smoothed is None or loess_smoothed.size == 0:\n",
    "                raise ValueError('LOESS returned no data')\n",
    "            # loess_smoothed[:,0] are x-values (floats). Map to nearest integer positions.\n",
    "            trend_pos = np.rint(loess_smoothed[:, 0]).astype(int)\n",
    "            # Clamp positions to valid row indices\n",
    "            trend_pos = np.clip(trend_pos, 0, len(monthly_data) - 1)\n",
    "            # Preserve order but remove duplicates\n",
    "            _, unique_idx = np.unique(trend_pos, return_index=True)\n",
    "            trend_pos = trend_pos[np.sort(unique_idx)]\n",
    "\n",
    "            # Build trend DataFrame. Use errors='coerce' when parsing dates to avoid crashes.\n",
    "            months = monthly_data['timestamp'].iloc[trend_pos]\n",
    "            trend_df = pd.DataFrame({\n",
    "                'Month': months.dt.strftime(DATE_FORMAT).values,\n",
    "                'Median Price': loess_smoothed[:, 1],\n",
    "                'Type': TREND_TYPE\n",
    "            })\n",
    "            # Add temporary key for sorting before dropping it\n",
    "            trend_df['Sort_Key'] = pd.to_datetime(trend_df['Month'], format=DATE_FORMAT, errors='coerce')\n",
    "            return trend_df.sort_values('Sort_Key').drop(columns=['Sort_Key'])\n",
    "        except Exception as e:\n",
    "            # Helpful debug output so the root cause is visible when running the notebook\n",
    "            print(f\"‚ùå Error during LOESS calculation ({TREND_TYPE}): {e}\")\n",
    "            try:\n",
    "                # If available, show small diagnostics\n",
    "                print(f\"  monthly_data rows={len(monthly_data)}, LOESS_FRAC={LOESS_FRAC}, LOESS_IT={LOESS_IT}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "            return pd.DataFrame({'Month': [], 'Median Price': [], 'Type': []})\n",
    "\n",
    "    def prepare_forecast_data(self, area_name):\n",
    "        if self.growth_pivot is None:\n",
    "            return None\n",
    "        area_growth = self.growth_pivot[self.growth_pivot['area_name_en'] == area_name]\n",
    "        if area_growth.empty:\n",
    "            return None\n",
    "        periods = area_growth['month'].unique()\n",
    "        forecast_data = {}\n",
    "        for period in periods:\n",
    "            period_data = area_growth[area_growth['month'] == period].iloc[0]\n",
    "            forecast_data[period] = {\n",
    "                'main': period_data['growth_factor'],\n",
    "                'upper': period_data['growth_factor_upper'],\n",
    "                'lower': period_data['growth_factor_lower']\n",
    "            }\n",
    "        return forecast_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc9d8744-9957-46fc-b584-293db7626efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anant\\OneDrive\\Desktop\\truEstates\\.conda\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\anant\\OneDrive\\Desktop\\truEstates\\.conda\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\anant\\OneDrive\\Desktop\\truEstates\\.conda\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ Running Analysis for Sample Input: Al Barsha South Fourth (2 B/R, 60 sqMt)\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PropertyPricePredictor' object has no attribute 'predict_and_analyze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     procedure_area \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;66;03m# sqMt    \u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# 2. Call the method and receive the combined DataFrame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_and_analyze\u001b[49m(\n\u001b[0;32m     25\u001b[0m         selected_area, rooms_en, floor_bin, swimming_pool, balcony, \n\u001b[0;32m     26\u001b[0m         elevator, metro, has_parking, procedure_area\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Execution complete. ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PropertyPricePredictor' object has no attribute 'predict_and_analyze'"
     ]
    }
   ],
   "source": [
    "# Assuming the entire PropertyPricePredictor class definition from your prompt is already defined above this block.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. Instantiate the predictor engine\n",
    "    engine = PropertyPricePredictor()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üöÄ Running Analysis for Sample Input: Al Barsha South Fourth (2 B/R, 60 sqMt)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # --- Define Input Features ---\n",
    "    selected_area = 'Al Hebaih Fourth'\n",
    "    rooms_en = '2 B/R'             \n",
    "    floor_bin = '11-20'            \n",
    "    swimming_pool = 1              # 1 for Yes, 0 for No\n",
    "    balcony = 1\n",
    "    elevator = 1\n",
    "    metro = 0\n",
    "    has_parking = 1\n",
    "    procedure_area = 60 # sqMt    \n",
    "\n",
    "    # 2. Call the method and receive the combined DataFrame\n",
    "    results_df = engine.predict_and_analyze(\n",
    "        selected_area, rooms_en, floor_bin, swimming_pool, balcony, \n",
    "        elevator, metro, has_parking, procedure_area\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"\\n--- Execution complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2cd0aa6-a64a-4607-ba98-b82454a79f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Median Price</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-08-2025</td>\n",
       "      <td>19484.890000</td>\n",
       "      <td>Prediction Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>19708.184572</td>\n",
       "      <td>Future Forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>19930.603201</td>\n",
       "      <td>Future Forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>20152.900051</td>\n",
       "      <td>Future Forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>20375.584729</td>\n",
       "      <td>Future Forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2026-01-01</td>\n",
       "      <td>20598.899320</td>\n",
       "      <td>Future Forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>20822.861869</td>\n",
       "      <td>Future Forecast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month  Median Price              Type\n",
       "0  01-08-2025  19484.890000  Prediction Point\n",
       "1  2025-09-01  19708.184572   Future Forecast\n",
       "2  2025-10-01  19930.603201   Future Forecast\n",
       "3  2025-11-01  20152.900051   Future Forecast\n",
       "4  2025-12-01  20375.584729   Future Forecast\n",
       "5  2026-01-01  20598.899320   Future Forecast\n",
       "6  2026-02-01  20822.861869   Future Forecast"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ace3e5-1778-40bb-8d8a-5ace285741cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
